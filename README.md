TriGraM
=======

Introduction
------------

Triple Graph based Meta-data storage - TriGraM

A brief history
---------------

The original motivation is described in
[my thesis](http://cdmd.cnki.com.cn/Article/CDMD-10487-1012268216.htm).

Preliminary version was developed as a simple XQuery program during 2011.2\~2011.8,
and can be run from [XQilla](http://xqilla.sourceforge.net/HomePage) command line,
the input source file is from [DMTF CIM](http://www.dmtf.org/standards/cim) model
and must be compiled by OpenPegasus, and the basic idea is to use translated
semantic model in helping storage resource management.

In late 2011, switch the whole tool-chain to Python and
[RDFLib](https://github.com/RDFLib/rdflib) for flexible development,
called [SEED](#seed), aims at efficient meta-data storage for distributed file
systems.

In late 2012, for the scalable consideration, the main framework
switched once more, to [Scala](http://www.scala-lang.org/) +
[Jena](http://jena.apache.org/), Scala provides the language-level parallelism,
and Jena is a comprehensive framework for both model manipulation and persistent
storage, the latter is implemented as
[TDB](http://jena.apache.org/documentation/tdb/).

### SEED

Storage of **Extemporal Ensemble Device**

Organize commodity storage devices with minimum cost to build a
loose-coupled system, which features dynamic
metadata-manager/storage-server/client nodes, and fast deployment.

How to use
----------

1.  deploy [sbt](https://github.com/harrah/xsbt/wiki) with
    [sbteclipse](https://github.com/typesafehub/sbteclipse), open sbt
    console in project root directory, type `update`, wait until all the
    dependencies are resolved.

2.  use `eclipse` to generate eclipse project, include `.project` and
    `.classpath`.

3.  use `compile`.

4.  use `copy-dep` to collect all jars into `target\scala-2.10\lib\`.

5.  use scripts in project root to execute, `trigram` for \*NIX and
    `trigram.cmd` for Windows.

6.  use `trigram -m` to translate designated resources to semantic models,
    the models can then be combined as one or imported into triple database,
    then be used for various purposes.

    triple database location is defined in 'TGM_DATA' and defaults to
    '$TGM_ROOT/.trigram'.

    Download CIM schema and extract the XML version, then translate it to get
    the CIM model, update the vocabulary if needed, that will be used in other
    modelers, especially those for modeling computer resource and organization.

    * CIM_All.owl: all-in-one version, complete huge model.

    * CIM_Base.owl ...: model group, which contains separate, dependent sub-models
      for use by dedicated modelers, can be imported when required,
      provide modeling flexibility.

    If several models are required to use together,
    they can then be combined by `trigram -c` or
    just put them into the same repository, by using `trigram -i <model>` to import.

    'dir(ex)/arc' modelers will use CIM vocabulary to generate models,
    which contain OWL:imports leads to CIM class models, generated by CimSchemaEx.
    These models can be gathered by `trigram -g` for independent use without
    the CIM repository or triple database.

    The purpose is to merge required sub-models into one aggregated model.
    The merged model can than be easily inferred, imported or transferred.

7.  SPARQL execution

    * use `trigram -q <SPARQL query>` for query, `trigram -u <SPARQL update>` for update.

    * or use `trigram` to enter command shell, and mode <query|update> to
      switch between query and update modes.

8.  Helper scripts in test directory

    * (accessory project) GenerateProtegeCatalog.scala

      scan designated directory and create a catalog file for Protege to load
      so that the models can be easily imported and processed.

    * (accessory project) PrepareTestDirectory.scala

      create a set of files and directories for testing.

    * cim/get-cim.sh

      show how to get the latest CIM schema from official web site

    * test/checksum-collect.sh

      collect checksum from designated directory to CSV file
      'test/checksum-names' can be used to carry the concept and property names

    * test/get-acad.sh

      download a set of meta-model for academic literature (for future use).

9.  Use [sbt assembly](https://github.com/sbt/sbt-assembly) to create a portable all-in-one JAR.

    Use `java -jar <JAR>` to run.

NOTE:

1.  `trigram` will search dependencies in `target\scala-2.10\lib\` (step 4).

2.  The sbt ivy cache should be located in a folder without spaces in its name.

3.  ivy cache relocation can be done through adding these parameters to
    sbt loader:

    JAVA\_OPTS=" -Dsbt.ivy.home=d:/java/sbt/.ivy2/
    -Dsbt.global.base=d:/java/sbt/.sbt/ "\$JAVA\_OPTS

Design
------

-   System architecture, communication and model draft:

    `doc/design.odg`

-   Brief introduction:

    `doc/oam.odt`

-   Command line interface:

      provides 5 entries:

      default entry: enter console

      1. '-h' show help

      2. '-v' show version

      3. '-i' import specified model into local triple storage

      4. '-q' query local storage

      5. '-u' update local storage

      6. '-c' combine multiple models

      7. '-V' generate CIM vocabulary from CIM schema XML 

      8. '-g' gather imported CIM class models into designated model

      9. '-m' invoke modeler 'MODELER' to translate specified source

Related Work
------------

Distributed File Systems: [GFS](http://labs.google.com/papers/gfs.html),
[HDFS](http://hadoop.apache.org/index.html), [Ceph](http://ceph.com/),
[Tahoe-LAFS](https://tahoe-lafs.org/trac/tahoe-lafs),
[Kosmos Distributed Filesystem](http://code.google.com/p/kosmosfs/),
[Quantcast File System](https://github.com/quantcast/qfs),
[Storage@home](http://cs.stanford.edu/people/beberg/Storage@home2007.pdf)

Triple Store: [Sesame](http://www.openrdf.org/) and
[Alibaba](http://www.openrdf.org/alibaba.jsp), more can be found in [W3C
LargeTripleStores](http://www.w3.org/wiki/LargeTripleStores)

Author
======

[ShiZhan](http://shizhan.github.com/) (c) 2013 [Apache License Version
2.0](http://www.apache.org/licenses/)
